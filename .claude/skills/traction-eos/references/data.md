# Data Component: Scorecards and Metrics

The Data Component replaces gut-feeling management with objective, weekly numbers. When everyone in the leadership team looks at the same 5-15 metrics every week, problems surface weeks earlier, accountability becomes automatic, and decision-making improves dramatically. This guide covers how to design a Scorecard, choose the right metrics, avoid common mistakes, and connect data to your Level 10 meetings.

## The Weekly Scorecard

A Scorecard is a one-page document that tracks 5-15 activity-based numbers weekly. It is reviewed in every Level 10 meeting. If a number is off track, it drops to the Issues List for IDS.

### Scorecard Design Principles

1. **Weekly cadence.** Monthly financials are too slow. By the time you see a monthly miss, you have lost four weeks of correction time. Weekly numbers give you early warning.
2. **Activity-based metrics.** Measure what people do (calls made, demos given), not just what happened (revenue, churn). Activities are leading indicators you can influence. Results are lagging indicators you can only observe.
3. **5-15 numbers.** Fewer than 5 means blind spots. More than 15 means noise. Most companies land on 8-12.
4. **Every number has an owner.** One person is accountable for each metric. Not a department. A name.
5. **Every number has a goal.** A number without a goal is just a data point. The goal creates the standard for red/green tracking.

## How to Choose Your Metrics

### The Vacation Test

Ask yourself: "If I went on vacation for four weeks with no phone or email, what 5-15 numbers would I want to see when I got back to know exactly how the business performed?"

This question forces you to identify the vital few numbers that genuinely indicate business health.

### Metric Selection by Category

| Category | What to Measure | Example Metrics |
|----------|----------------|-----------------|
| **Revenue** | Money coming in | Weekly revenue, new deal value, average deal size |
| **Pipeline** | Future revenue | New leads generated, qualified opportunities, proposals sent |
| **Sales Activity** | Effort going in | Calls made, demos completed, meetings booked |
| **Customer Health** | Retention and satisfaction | Churn rate, NPS, support tickets resolved, renewal rate |
| **Operations** | Delivery quality | On-time delivery %, defect rate, utilization rate |
| **Financial** | Cash and profitability | Cash balance, AR over 60 days, gross margin |
| **People** | Team health | Open positions, employee satisfaction score, training hours |

### Leading vs. Lagging Indicators

Understanding the difference between leading and lagging indicators is critical to building an effective Scorecard.

| Type | Definition | Response Time | Examples |
|------|-----------|--------------|---------|
| **Leading** | Measures input activities that drive future results | Can be corrected this week | Calls made, proposals sent, content published |
| **Lagging** | Measures output results that have already occurred | Can only be observed, not changed retroactively | Revenue, churn, profit margin |

**The ideal Scorecard is 70% leading indicators and 30% lagging indicators.** Leading indicators let you course-correct before lagging indicators go red.

### Building the Metric Chain

Great Scorecards show the cause-and-effect chain from activity to result:

```
Outbound emails (leading)
  → Meetings booked (leading)
    → Demos given (leading)
      → Proposals sent (leading)
        → Deals closed (lagging)
          → Revenue (lagging)
```

When revenue drops, you can trace back through the chain to find where the breakdown occurred. Was it fewer emails? Lower meeting conversion? Longer sales cycles? The Scorecard tells you.

## Every Number Has an Owner

### The Ownership Rule

Each metric on the Scorecard is assigned to one person. That person:
- Reports the number weekly in the Level 10 meeting
- Explains when the number is off track
- Owns the plan to get it back on track
- Drops it to the Issues List when help is needed

**Ownership does not mean they do all the work.** The VP of Sales owns the "demos completed" metric even though individual reps give the demos. Ownership means accountability for the result.

### Assigning Owners

| Metric | Owner | Why |
|--------|-------|-----|
| Weekly revenue | Head of Sales | Directly manages the revenue-generating team |
| New leads | Head of Marketing | Responsible for lead generation strategy |
| On-time delivery | Head of Operations | Manages delivery team and processes |
| Cash balance | Head of Finance | Manages cash flow and collections |
| Employee satisfaction | Head of People/Integrator | Responsible for culture and retention |

## Every Number Has a Goal

### Setting Goals

Goals should be based on:
- **Historical performance:** What have you averaged over the past 13 weeks?
- **Growth targets:** What does the 1-Year Plan require?
- **Capacity:** What is realistically achievable with current resources?

### Goal-Setting Template

| Metric | 13-Week Average | 1-Year Plan Requires | Goal |
|--------|----------------|---------------------|------|
| Weekly revenue | $42K | $60K/week by Q4 | $45K (Q1), $50K (Q2), $55K (Q3), $60K (Q4) |
| New leads | 80 | 120/week | 90 (Q1), 100 (Q2), 110 (Q3), 120 (Q4) |
| Demos completed | 15 | 25/week | 18 (Q1), 20 (Q2), 22 (Q3), 25 (Q4) |

Goals can be updated quarterly during the Quarterly Session. Do not change them mid-quarter unless the business model fundamentally changes.

## Red/Green Tracking

### How It Works

Each week, every metric is marked as green (on track) or red (off track):

- **Green:** Number meets or exceeds the goal
- **Red:** Number misses the goal

When a number is red, the owner has two options:
1. **Explain and fix:** The issue is understood and a correction is underway
2. **Drop to IDS:** The issue needs the team's input to solve

### Tracking Format

| Metric | Owner | Goal | W1 | W2 | W3 | W4 | W5 | W6 | W7 | W8 | W9 | W10 | W11 | W12 | W13 |
|--------|-------|------|----|----|----|----|----|----|----|----|----|----|-----|-----|-----|
| Revenue | Pat | $50K | G | G | R | G | G | G | R | G | G | G | G | G | G |
| Leads | Alex | 100 | G | R | R | G | G | G | G | G | G | R | G | G | G |
| Demos | Jordan | 20 | G | G | G | G | R | G | G | G | G | G | G | R | G |

**The 13-week trailing view** is essential. It shows trends, not just snapshots. Three consecutive red weeks on the same metric is a systemic issue that must be IDS'd.

## Scorecard Templates by Department

### Sales Scorecard

| Metric | Owner | Goal | Frequency |
|--------|-------|------|-----------|
| New qualified leads | SDR Manager | 50/week | Weekly |
| Discovery calls completed | Sales Manager | 25/week | Weekly |
| Proposals sent | Sales Manager | 10/week | Weekly |
| Deals closed | Sales Manager | 5/week | Weekly |
| New revenue booked | VP Sales | $75K/week | Weekly |
| Pipeline value | VP Sales | $500K+ | Weekly |
| Win rate | VP Sales | >25% | Weekly |

### Marketing Scorecard

| Metric | Owner | Goal | Frequency |
|--------|-------|------|-----------|
| Website visitors | Marketing Manager | 5,000/week | Weekly |
| Content pieces published | Content Lead | 3/week | Weekly |
| MQLs generated | Demand Gen Lead | 100/week | Weekly |
| Email open rate | Email Manager | >25% | Weekly |
| Social engagement | Social Lead | 500 interactions/week | Weekly |
| Cost per lead | VP Marketing | <$50 | Weekly |

### Operations Scorecard

| Metric | Owner | Goal | Frequency |
|--------|-------|------|-----------|
| Projects delivered on time | Project Manager | >90% | Weekly |
| Customer satisfaction (CSAT) | Support Lead | >4.5/5 | Weekly |
| Support tickets resolved | Support Lead | <24hr avg | Weekly |
| Utilization rate | Operations Manager | 75-85% | Weekly |
| Quality issues | QA Lead | <3/week | Weekly |
| Capacity available | Operations Manager | >15% buffer | Weekly |

### Finance Scorecard

| Metric | Owner | Goal | Frequency |
|--------|-------|------|-----------|
| Cash balance | Controller | >$300K | Weekly |
| AR over 60 days | AR Manager | <$50K | Weekly |
| Weekly cash burn | CFO | <$40K | Weekly |
| Invoices sent within 48hr | AR Manager | 100% | Weekly |
| Payroll accuracy | Payroll Lead | 100% | Weekly |

## Common Scorecard Mistakes

| Mistake | Why It Hurts | Fix |
|---------|-------------|-----|
| **Too many metrics (>15)** | Information overload, no focus | Cut to the vital few that indicate health |
| **All lagging indicators** | Cannot course-correct, only observe | Add leading indicators: activities and inputs |
| **No owner assigned** | "Someone will handle it" means nobody does | One name per metric, no exceptions |
| **Goals too easy** | Scorecard is always green, masks problems | Set goals that require effort but are achievable |
| **Goals too hard** | Scorecard is always red, creates learned helplessness | Base goals on 13-week average plus realistic stretch |
| **Not reviewed weekly** | Data goes stale, accountability disappears | Scorecard is agenda item #2 in every Level 10 meeting |
| **Monthly instead of weekly** | Lose 4 weeks of correction time | Convert monthly metrics to weekly proxies |
| **Vanity metrics** | Numbers that look good but do not drive the business | Replace with metrics tied to revenue or customer outcomes |
| **No trending view** | See this week but miss the pattern | Always show 13 trailing weeks |
| **Changing metrics too often** | No baseline for comparison | Lock metrics for at least one full quarter |

## Activity-Based vs. Results-Based Metrics

### When to Use Each

**Activity-based metrics** are best when:
- You need early warning signals
- You want to influence behavior
- The sales cycle is long (weeks or months)
- You are building new processes

**Results-based metrics** are best when:
- You need to confirm the activities are producing outcomes
- You are reporting to a board or investors
- The metric is a business health vital sign (cash, churn, revenue)

### Balanced Scorecard Example

```
LEADING (Activities)          LAGGING (Results)
├── Calls made                ├── Revenue
├── Demos given               ├── Profit margin
├── Proposals sent            ├── Customer churn
├── Content published         ├── NPS score
├── Candidates interviewed    └── Cash balance
└── Tickets resolved
```

A healthy Scorecard has both types in roughly a 70/30 split favoring leading indicators.

## How the Scorecard Connects to Level 10 Meetings

The Scorecard is reviewed in the first 5 minutes of the Level 10 meeting, right after the Segue. Here is the protocol:

### Scorecard Review Protocol

1. **Display the Scorecard** so all attendees can see it (projector, shared screen, or printed)
2. **Go metric by metric.** The owner reads the number and states "on track" or "off track."
3. **No discussion during review.** If a number is off track, the owner simply states the number and says "dropping to Issues List."
4. **Time limit: 5 minutes.** This is a quick scan, not a deep dive. Deep dives happen during IDS.
5. **Pattern recognition.** If the same metric is red three weeks in a row, it is automatically the top issue for IDS.

### From Scorecard to IDS

When a metric is off track, the flow is:

```
Scorecard review → Metric is red → Owner drops to Issues List
  → During IDS, team identifies root cause
    → Action items assigned (who, what, by when)
      → Next week: check if action item is complete
        → Check if metric returned to green
```

This weekly cycle ensures no problem goes unaddressed for more than one week. The Scorecard is the early warning system. The Level 10 meeting is the response mechanism.

## Building Your First Scorecard

### Week 1 Checklist

- [ ] Brainstorm 20-30 possible metrics with the leadership team
- [ ] Apply the vacation test to narrow to 5-15
- [ ] Assign one owner per metric
- [ ] Set goals based on 13-week historical average plus 10% stretch
- [ ] Create a simple spreadsheet with 13 trailing weeks
- [ ] Commit to reviewing it in the next Level 10 meeting

### Weeks 2-4: Refine

- [ ] Remove metrics that are always green (too easy or not meaningful)
- [ ] Replace metrics that nobody understands
- [ ] Adjust goals that were set too high or too low
- [ ] Ensure every department has at least one metric on the Scorecard

### Month 2+: Mature

- [ ] Everyone can recite the Scorecard metrics from memory
- [ ] The team looks forward to Scorecard review (it creates clarity)
- [ ] Off-track metrics are solved quickly through IDS
- [ ] New hires are shown the Scorecard in their first week
- [ ] Department-level scorecards cascade from the company Scorecard
